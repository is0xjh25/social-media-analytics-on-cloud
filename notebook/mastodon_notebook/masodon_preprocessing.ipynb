{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from happiness_mining import scoring as hs\n",
    "from happiness_mining import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghopark/Documents/GitHub/social-media-analytics-on-cloud/notebook/mastodon_notebook/happiness_mining/nlp.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  tmp = BeautifulSoup(text, features=\"html.parser\").text\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/raw/mastodon.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.loc[df[\"language\"]==\"en\"]\n",
    "df['token'] = df['content'].apply(nlp.create_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>language</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;If there's any team that could trick this o...</td>\n",
       "      <td>2023-04-26 04:27:53+00:00</td>\n",
       "      <td>['nba']</td>\n",
       "      <td>en</td>\n",
       "      <td>[team, could, trick, cp3, sun, nba]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;This piece was damaged in storage (scratche...</td>\n",
       "      <td>2023-04-26 04:27:51+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>[piec, damag, storag, scratch, much, small, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;ðŸ‡ºðŸ‡¸ðŸ‡ºðŸ‡¦Draft resolution â€˜Ukrainian Victoryâ€™ pr...</td>\n",
       "      <td>2023-04-26 04:27:54+00:00</td>\n",
       "      <td>['wanteddeadoralive', '9yearsofwarinukraine', ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[ðŸ‡ºðŸ‡¸ðŸ‡ºðŸ‡¦draft, resolut, â€˜, ukrainian, victori, â€™,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;AFL does not regret past concussion managem...</td>\n",
       "      <td>2023-04-26 04:27:37+00:00</td>\n",
       "      <td>['news']</td>\n",
       "      <td>en</td>\n",
       "      <td>[afl, regret, past, concuss, manag, say, under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;\"Our whole spiritual transformation brings ...</td>\n",
       "      <td>2023-04-26 04:27:55+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>[whole, spiritu, transform, bring, us, point, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>&lt;p&gt;&lt;span class=\"h-card\"&gt;&lt;a href=\"https://masto...</td>\n",
       "      <td>2023-05-01 23:18:25+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>[davidslack, ,, man, worth, knowing.if, n't, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153164</th>\n",
       "      <td>&lt;p&gt;Still working on the Terminator Chaplain! S...</td>\n",
       "      <td>2023-05-01 17:42:54+00:00</td>\n",
       "      <td>['paintingwarhammer', 'gamesworkshop', 'warham...</td>\n",
       "      <td>en</td>\n",
       "      <td>[still, work, termin, chaplain, !, sorri, abse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153166</th>\n",
       "      <td>&lt;p&gt;Earthquake at 11:16 AM, 5 km north-west of ...</td>\n",
       "      <td>2023-05-01 23:18:32+00:00</td>\n",
       "      <td>['mmi3', 'mag2', 'eqnz']</td>\n",
       "      <td>en</td>\n",
       "      <td>[earthquak, 11:16, ,, 5, km, north-west, poran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153167</th>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://globalnews.ca/news/9662145...</td>\n",
       "      <td>2023-05-01 18:28:01+00:00</td>\n",
       "      <td>['yeg', 'yegwx', 'yegtraffic']</td>\n",
       "      <td>en</td>\n",
       "      <td>[yegwx, yegtraff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153168</th>\n",
       "      <td>&lt;p&gt;I'd join Procrastinators Anonymous, but nob...</td>\n",
       "      <td>2023-05-01 23:18:44+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>['d, join, procrastin, anonym, ,, nobodi, gott...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126930 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  \\\n",
       "0       <p>If there's any team that could trick this o...   \n",
       "1       <p>This piece was damaged in storage (scratche...   \n",
       "2       <p>ðŸ‡ºðŸ‡¸ðŸ‡ºðŸ‡¦Draft resolution â€˜Ukrainian Victoryâ€™ pr...   \n",
       "3       <p>AFL does not regret past concussion managem...   \n",
       "4       <p>\"Our whole spiritual transformation brings ...   \n",
       "...                                                   ...   \n",
       "153163  <p><span class=\"h-card\"><a href=\"https://masto...   \n",
       "153164  <p>Still working on the Terminator Chaplain! S...   \n",
       "153166  <p>Earthquake at 11:16 AM, 5 km north-west of ...   \n",
       "153167  <p><a href=\"https://globalnews.ca/news/9662145...   \n",
       "153168  <p>I'd join Procrastinators Anonymous, but nob...   \n",
       "\n",
       "                       created_at  \\\n",
       "0       2023-04-26 04:27:53+00:00   \n",
       "1       2023-04-26 04:27:51+00:00   \n",
       "2       2023-04-26 04:27:54+00:00   \n",
       "3       2023-04-26 04:27:37+00:00   \n",
       "4       2023-04-26 04:27:55+00:00   \n",
       "...                           ...   \n",
       "153163  2023-05-01 23:18:25+00:00   \n",
       "153164  2023-05-01 17:42:54+00:00   \n",
       "153166  2023-05-01 23:18:32+00:00   \n",
       "153167  2023-05-01 18:28:01+00:00   \n",
       "153168  2023-05-01 23:18:44+00:00   \n",
       "\n",
       "                                                 hashtags language  \\\n",
       "0                                                 ['nba']       en   \n",
       "1                                                      []       en   \n",
       "2       ['wanteddeadoralive', '9yearsofwarinukraine', ...       en   \n",
       "3                                                ['news']       en   \n",
       "4                                                      []       en   \n",
       "...                                                   ...      ...   \n",
       "153163                                                 []       en   \n",
       "153164  ['paintingwarhammer', 'gamesworkshop', 'warham...       en   \n",
       "153166                           ['mmi3', 'mag2', 'eqnz']       en   \n",
       "153167                     ['yeg', 'yegwx', 'yegtraffic']       en   \n",
       "153168                                                 []       en   \n",
       "\n",
       "                                                    token  \n",
       "0                     [team, could, trick, cp3, sun, nba]  \n",
       "1       [piec, damag, storag, scratch, much, small, st...  \n",
       "2       [ðŸ‡ºðŸ‡¸ðŸ‡ºðŸ‡¦draft, resolut, â€˜, ukrainian, victori, â€™,...  \n",
       "3       [afl, regret, past, concuss, manag, say, under...  \n",
       "4       [whole, spiritu, transform, bring, us, point, ...  \n",
       "...                                                   ...  \n",
       "153163  [davidslack, ,, man, worth, knowing.if, n't, f...  \n",
       "153164  [still, work, termin, chaplain, !, sorri, abse...  \n",
       "153166  [earthquak, 11:16, ,, 5, km, north-west, poran...  \n",
       "153167                                  [yegwx, yegtraff]  \n",
       "153168  ['d, join, procrastin, anonym, ,, nobodi, gott...  \n",
       "\n",
       "[126930 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from happiness_mining import happiness_database as hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_couch = \"http://admin:admin@172.26.131.83:5984\"\n",
    "db_name = \"mastodon\"\n",
    "config = {\"COUCHDB_URL\": url_couch, \"DB_NAME\": db_name, \"MODEL_PATH\":\"./happiness_mining/happy_model.sav\", \"VECTORIZOR_PATH\":\"./happiness_mining/happy_vector.sav\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(config[\"MODEL_PATH\"], \"rb\"))\n",
    "vectorizor = pickle.load(open(config[\"VECTORIZOR_PATH\"], \"rb\"))\n",
    "couch = hd.Couchdb(config[\"COUCHDB_URL\"])\n",
    "db = couch.set_db(config[\"DB_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def happiness_behavour(content):\n",
    "    try:\n",
    "        tf_idf_vectorized = vectorizor.transform(pd.Series([content]))\n",
    "        df_tfdf = pd.DataFrame(\n",
    "            tf_idf_vectorized.todense(),\n",
    "            columns=vectorizor.get_feature_names_out(),\n",
    "        )\n",
    "        prediction = model.predict(df_tfdf)\n",
    "        return prediction[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghopark/Documents/GitHub/social-media-analytics-on-cloud/notebook/mastodon_notebook/happiness_mining/nlp.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  tmp = BeautifulSoup(text, features=\"html.parser\").text\n",
      "/Users/jonghopark/Documents/GitHub/social-media-analytics-on-cloud/notebook/mastodon_notebook/happiness_mining/nlp.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  tmp = BeautifulSoup(text, features=\"html.parser\").text\n",
      "/Users/jonghopark/Documents/GitHub/social-media-analytics-on-cloud/notebook/mastodon_notebook/happiness_mining/nlp.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  tmp = BeautifulSoup(text, features=\"html.parser\").text\n",
      "/Users/jonghopark/Documents/GitHub/social-media-analytics-on-cloud/notebook/mastodon_notebook/happiness_mining/nlp.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  tmp = BeautifulSoup(text, features=\"html.parser\").text\n"
     ]
    }
   ],
   "source": [
    "hmodel = hs.happiness_score()\n",
    "\n",
    "count_non_behav = 0\n",
    "count_non_score = 0\n",
    "count_non_en = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    language = row[\"language\"]\n",
    "    if language == \"en\":\n",
    "        content = row[\"content\"]\n",
    "        # print(content)\n",
    "        tokens = nlp.create_tokens(content)\n",
    "        score = hmodel.scoring_by_text(tokens)\n",
    "        if score != 0:\n",
    "            created_at = str(row[\"created_at\"])\n",
    "            tags = []\n",
    "            happiness_behaviour = happiness_behavour(content)\n",
    "            if happiness_behaviour is not None:\n",
    "                data = {\n",
    "                    \"content\": content,\n",
    "                    \"created_at\": created_at,\n",
    "                    \"language\": language,\n",
    "                    \"hashtags\": tags,\n",
    "                    \"tokens\": tokens,\n",
    "                    \"score\": score,\n",
    "                    \"happiness_behaviour\": happiness_behaviour,\n",
    "                }\n",
    "                # Only include necessary keys in the JSON output\n",
    "                keys_to_include = [\n",
    "                    \"account_id\",\n",
    "                    \"content\",\n",
    "                    \"created_at\",\n",
    "                    \"language\",\n",
    "                    \"hashtags\",\n",
    "                    \"tokens\",\n",
    "                    \"score\",\n",
    "                    \"happiness_behaviour\",\n",
    "                ]\n",
    "                filtered_data = {\n",
    "                    k: v for k, v in data.items() if k in keys_to_include\n",
    "                }\n",
    "                db.save(filtered_data)\n",
    "            else:\n",
    "                count_non_behav += 1\n",
    "        else:\n",
    "            count_non_score += 1\n",
    "    else:\n",
    "        count_non_en += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_non_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_non_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7813"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_non_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hs.happiness_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# df[\"t_score\"] = 0\n",
    "# df[\"w_score\"] = 0\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     words += row[\"token\"]\n",
    "#     score = model.scoring_by_text(row[\"token\"])\n",
    "#     df.loc[i, \"t_score\"] = score\n",
    "\n",
    "# model.set_whole_words(words)\n",
    "# for i, row in df.iterrows():\n",
    "#     score = model.scoring_in_whole(row[\"token\"])\n",
    "#     df.loc[i, \"w_score\"] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath = \"../data/curated/mastodon_processed.csv\"\n",
    "# df[[\"created_at\",\"hashtags\",\"language\",\"token\",\"t_score\",\"w_score\"]].to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(outpath, index_col=0) \n",
    "# df[\"hashtags\"] = df[\"hashtags\"].str.strip('][').str.split(', ')\n",
    "# df[\"token\"] = df[\"token\"].str.strip('][').str.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
